{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6tmn9u6Ylxx1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import plot_model\n",
    "from tensorflow.keras.utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Lw2VRHmfmih7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "VGGdemo = Sequential(name='VGGdemo')\n",
    "VGGdemo.add(Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "VGGdemo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "VGGdemo.add(Flatten())\n",
    "VGGdemo.add(Dense(128, activation='relu'))\n",
    "VGGdemo.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2rRRVxJcnE8r"
   },
   "outputs": [],
   "source": [
    "VGGdemo.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhE5tislnGy1",
    "outputId": "0cfb1ae7-6c20-41a4-bd8f-d2100bcb50ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caps', 'Pants', 'Shoes', 'Shorts', 'tshirt']\n",
      "Types of clothes found:  5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "dataset_path = os.listdir(\"D:\\\\Teachnook\\\\Project\\\\Code\\\\Resized\")\n",
    "\n",
    "clothes_types = os.listdir(\"D:\\\\Teachnook\\\\Project\\\\Code\\\\Resized\")\n",
    "print (clothes_types)\n",
    "\n",
    "print(\"Types of clothes found: \", len(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "c7fjBOvInK_V"
   },
   "outputs": [],
   "source": [
    "clothes = []\n",
    "\n",
    "for item in clothes_types:\n",
    " all_clothes = os.listdir(\"D:\\\\Teachnook\\\\Project\\\\Code\\\\Resized\" + '/' +item)\n",
    "\n",
    " for cloth in all_clothes:\n",
    "    clothes.append((item, str(\"D:\\\\Teachnook\\\\Project\\\\Code\\\\Resized\" + '/' +item) + '/' + cloth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9lROlhtntu0",
    "outputId": "86ec4127-2007-4a1d-f935-5aa5fe2c3224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cloth type                                           image\n",
      "0       Caps    D:\\Teachnook\\Project\\Code\\Resized/Caps/1.jpg\n",
      "1       Caps   D:\\Teachnook\\Project\\Code\\Resized/Caps/10.jpg\n",
      "2       Caps  D:\\Teachnook\\Project\\Code\\Resized/Caps/100.jpg\n",
      "3       Caps  D:\\Teachnook\\Project\\Code\\Resized/Caps/101.jpg\n",
      "4       Caps  D:\\Teachnook\\Project\\Code\\Resized/Caps/102.jpg\n"
     ]
    }
   ],
   "source": [
    "clothes_df = pd.DataFrame(data=clothes, columns=['cloth type', 'image'])\n",
    "print(clothes_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfXbwpMZoQeF",
    "outputId": "10f08b9b-4fd8-4d00-91bf-defc413e58e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of clothes in the dataset:  7746\n",
      "clothes in each category: \n",
      "cloth type\n",
      "tshirt    1993\n",
      "Pants     1774\n",
      "Shoes     1772\n",
      "Shorts    1517\n",
      "Caps       690\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of clothes in the dataset: \", len(clothes_df))\n",
    "\n",
    "cloth_count = clothes_df['cloth type'].value_counts()\n",
    "\n",
    "print(\"clothes in each category: \")\n",
    "print(cloth_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "G2V3fKi8T9Nb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "path = \"D:\\\\Teachnook\\\\Project\\\\Code\\\\Resized\\\\\"\n",
    "\n",
    "\n",
    "im_size = 224\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in clothes_types:\n",
    "    data_path = path + str(i)\n",
    "    filenames = [i for i in os.listdir(data_path) ]\n",
    "\n",
    "    for f in filenames:\n",
    "        img = cv2.imread(data_path + '/' + f)\n",
    "        img = cv2.resize(img, (im_size, im_size))\n",
    "        images.append(img)\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TN5iwVskT_ZX",
    "outputId": "6d41c70a-e075-4cce-e4dd-c58b4df22992"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7746, 224, 224, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "images = images.astype('float32') / 255.0\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ne7hUDy6UAyU",
    "outputId": "aa70aa0a-d741-440e-fd99-99c472ad542d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "y=clothes_df['cloth type'].values\n",
    "\n",
    "y_labelencoder = LabelEncoder ()\n",
    "y = y_labelencoder.fit_transform (y)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4u-P4cjTUCLV"
   },
   "outputs": [],
   "source": [
    "y = np.array(labels) \n",
    "y = y.reshape(-1, 1)\n",
    "onehotencoder = OneHotEncoder(sparse_output=False)\n",
    "Y = onehotencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRO-xNaGUDjy",
    "outputId": "871064b7-02d6-46fc-d734-e2094096df7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images: (7746, 224, 224, 3)\n",
      "Shape of labels (Y): (7746, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of images:\", images.shape)\n",
    "print(\"Shape of labels (Y):\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPTQvMRjUE2i",
    "outputId": "1d0ed62d-4ad0-4d68-986a-8cdc732d08f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6196, 224, 224, 3)\n",
      "(6196, 5)\n",
      "(1550, 224, 224, 3)\n",
      "(1550, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "images, Y = shuffle(images, Y, random_state=1)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVIQ6sS-UG-6",
    "outputId": "aa0be7b9-7a25-4d4b-cda8-525d3f770278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "195/195 [==============================] - 72s 362ms/step - loss: 1.0593 - accuracy: 0.5959\n",
      "Epoch 2/10\n",
      "195/195 [==============================] - 70s 358ms/step - loss: 0.7047 - accuracy: 0.7420\n",
      "Epoch 3/10\n",
      "195/195 [==============================] - 71s 363ms/step - loss: 0.5199 - accuracy: 0.8207\n",
      "Epoch 4/10\n",
      "195/195 [==============================] - 70s 361ms/step - loss: 0.4319 - accuracy: 0.8472\n",
      "Epoch 5/10\n",
      "195/195 [==============================] - 70s 361ms/step - loss: 0.3851 - accuracy: 0.8667\n",
      "Epoch 6/10\n",
      "195/195 [==============================] - 72s 370ms/step - loss: 0.3155 - accuracy: 0.8909\n",
      "Epoch 7/10\n",
      "195/195 [==============================] - 72s 369ms/step - loss: 0.2642 - accuracy: 0.9124\n",
      "Epoch 8/10\n",
      "195/195 [==============================] - 72s 369ms/step - loss: 0.2844 - accuracy: 0.9079\n",
      "Epoch 9/10\n",
      "195/195 [==============================] - 72s 372ms/step - loss: 0.1970 - accuracy: 0.9380\n",
      "Epoch 10/10\n",
      "195/195 [==============================] - 72s 371ms/step - loss: 0.1669 - accuracy: 0.9477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7870d848e170>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGGdemo.fit(train_x, train_y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VHmfMm2UIdg",
    "outputId": "b2a7c94c-7f6b-46ec-e14d-0caea78fe104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGdemo model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "VGGdemo.save('VGGdemo_trained_model.keras')\n",
    "\n",
    "print(\"VGGdemo model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lTr_HsgUPcA",
    "outputId": "bcb0ebd0-95f9-4242-c6f4-1f81c3c218f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 5s 103ms/step - loss: 0.3738 - accuracy: 0.8745\n",
      "Loss = 0.3738441467285156\n"
     ]
    }
   ],
   "source": [
    "preds = VGGdemo.evaluate(test_x, test_y)\n",
    "print (\"Loss = \" + str(preds[0]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
